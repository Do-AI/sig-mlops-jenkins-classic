{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps with Seldon and Jenkins Classic\n",
    "\n",
    "This repository shows how you can build a Jenkins Classic pipeline to enable Continuous Integration and Continuous Delivery (CI/CD) on your Machine Learning models leveraging Seldon for deployment.\n",
    "This CI/CD pipeline will allow you to:\n",
    "\n",
    "- Run unit tests using Jenkins Classic.\n",
    "- Run end-to-end tests for your model with KIND (Kubernetes in Docker).\n",
    "- Promote your model as a across multiple (staging / prod) environments.\n",
    "\n",
    "To showcase these features we will implement add continuous integration and delivery to three different models. \n",
    "You can find these under the `/models` folder.\n",
    "As we shall see, each of them will require a [different approach to deployment](#Use-Cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CI/CD Pipeline\n",
    "\n",
    "The diagram below provides a high level overview of the CI/CD pipeline.\n",
    "It includes an overview of all the different types of repositories, together with the stakeholders that are the primary contributors of each, as well as the Kubernetes environments in which the applications are deployed.\n",
    "\n",
    "The key pieces to note on the diagram are:\n",
    "\n",
    "- There are different types of environments with different restrictions and behaviours, e.g. staging and production.\n",
    "- It’s possible to have more than one environment for each type (as the type is just what would give it a specific type of config/behaviour).\n",
    "- The environments are by default in the same cluster (as namespaces), however it’s also possible to configure them across different clusters.\n",
    "- Each of the green boxes is a single repository, but it can also have a mono-repo approach, whereby each of the white boxes is a folder within a repo.\n",
    "\n",
    "![CI/CD Pipeline](./images/pipeline-architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model implementation repository\n",
    "\n",
    "From a high-level point of view, when a model implementation repository is updated by a Data Scientist or ML Engineer, the Jenkins CI will push changes to the [GitOps repository](#gitops-repository). This enables the following workflow:\n",
    "\n",
    "1. A Data Scientist or ML Engineer trains a new model.\n",
    "2. The Data Scientist or ML Engineer pushes the updated configuration to the model implementation repository.\n",
    "3. The CI tool automatically builds and tests the model implementation.\n",
    "4. The CI tool automatically pushes the change into the GitOps staging repository.\n",
    "5. The CI tool automatically opens a PR into the GitOps production repository.\n",
    "\n",
    "One key point to highlight which may not be obvious by just looking at the diagram is that in this phase of model implementation, the example above showcases how we can leverage a re-usable model server - that is, reusing a pre-built docker image instead of building one every time.\n",
    "If there are more custom requirements, the user is in full control of the steps performed by the CI Platform Jenkins.\n",
    "This means that it is also possible to build s2i wrapped components which may require training the image every time.\n",
    "\n",
    "#### Why a new repo for every model?\n",
    "\n",
    "A new model implementation repo is currently created because it provides us with a way to separate the “Model Deployment” phase and the “Model Training/Experimentation” phase, and allows us to use the repo as the integration between any frameworks that can serve as sources of models (MLFlow, Kubeflow, Spark, etc).\n",
    "The repo is able to store any metadata, IDs, and configuration files required, and is processed through the CI pipeline every time it is modified. \n",
    "\n",
    "#### Building a docker image in model implementation repository\n",
    "\n",
    "Whilst most of the times users of this approach will be leveraging re-usable model servers such as the SKLearn model server, it is also possible to build a docker image every single time (i.e. build a non-reusable model every time a model changes).\n",
    "This can be be done by adding the relevant steps which would most often include the s2i utility.\n",
    "This may be desired if there are non-standard linux libraries or non-standard depdencies that need to be re-installed every time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitOps repository\n",
    "\n",
    "**TODO:** All resources? Helm charts or just specs?\n",
    "\n",
    "The state of each of our environments (e.g. production or staging) is stored on a GitOps repository.\n",
    "This repository contains all the different Kubernetes resources that have been deployed to each cluster.\n",
    "It is linked through ArgoCD to each of our Kubernetes clusters (or namespaces) so that a change in the repository triggers an update of our environment.\n",
    "\n",
    "When the deployment configuration of a machine learning model implementation is updated, this will automatically make the changes available through a PR to the respective manager/tech-lead/approver.\n",
    "This step will enable the end to end machine learning model promotion to be reviewed and approved by the respective individual.\n",
    "\n",
    "The manager/tech-lead will have to approve the PR before it can be merged.\n",
    "Once it’s approved, it will be merged into the GitOps repo, which will immediately trigger the update in the production namespace/cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-usable model server repository\n",
    "\n",
    "If there is a need for a new reusable model server, then it’s possible to do so by creating a repository which would follow a different path.\n",
    "This would be different to the model implementation repository as it would only be built once in a while, whilst the model server would be built multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Set up\n",
    "\n",
    "As a pre-requisite you need to ensure that have access to a Kubernetes cluster.\n",
    "In particular, this guide requires the following pre- requisites:\n",
    "\n",
    "- A Kubernetes cluster running v1.13+.\n",
    "- Jenkins Classic installed in your cluster.\n",
    "- Seldon Core v0.5.1 installed in your cluster.\n",
    "\n",
    "**TODO:** Add note on ArgoCD (or Seldon Deploy??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jenkins Config\n",
    "\n",
    "The configurations required in the Jenkins server are:\n",
    "\n",
    "- Install the GitHub Plugin [(for automated webhook triggers)](https://support.cloudbees.com/hc/en-us/articles/115003015691-GitHub-Webhook-Non-Multibranch-Jobs).\n",
    "- Provide a GitHub token with read access so it can clone relevant repositories.\n",
    "- Set-up webhooks so that GitHub can send push requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cases\n",
    "\n",
    "**TODO:** Add links to separate notebooks.\n",
    "\n",
    "This guide goes through three different methods to build and deploy your model.\n",
    "\n",
    "- Using Seldon pre-built re-usable model servers. \n",
    "- Using custom re-usable servers.\n",
    "- Using custom servers with an embedded model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diving into our continuous integration\n",
    "\n",
    "**TODO:** Make this section general (applicable to the diff models)!\n",
    "\n",
    "**TODO:** Use Jenkins Classic instead of Jenkins X\n",
    "\n",
    "We have now separated our model development into two chunks: \n",
    "\n",
    "* The first one involves the creation of a model serve, and the second one involves the CI of the model server, and the second involves the deployment of models that create the model.\n",
    "\n",
    "\n",
    "## Using the Jenkins X pipeline\n",
    "\n",
    "In order to do this we will be able to first run some tests and the push to the docker repo.\n",
    "\n",
    "For this we will be leveraging the Jenkins X file, we'll first start with a simple file that just runs the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jenkins-x.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile jenkins-x.yml\n",
    "buildPack: none\n",
    "pipelineConfig:\n",
    "  pipelines:\n",
    "    release:\n",
    "      pipeline:\n",
    "        agent:\n",
    "          image: seldonio/core-builder:0.4\n",
    "        stages:\n",
    "          - name: test-sklearn-server\n",
    "            steps:\n",
    "            - name: run-tests\n",
    "              command: make\n",
    "              args:\n",
    "              - install_dev\n",
    "              - test\n",
    "    pullRequest:\n",
    "      pipeline:\n",
    "        agent:\n",
    "          image: seldonio/core-builder:0.4\n",
    "        stages:\n",
    "          - name: test-sklearn-server\n",
    "            steps:\n",
    "            - name: run-tests\n",
    "              command: make\n",
    "              args:\n",
    "              - install_dev\n",
    "              - test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `jenkins-x.yml` file is pretty easy to understand if we read through the different steps.\n",
    "\n",
    "Basically we can define the steps of what happens upon `release` - i.e. when a PR / Commit is added to master - and what happens upon `pullRequest` - whenever someone opens a pull request.\n",
    "\n",
    "You can see that the steps are exactly the same for both release and PR for now - namely, we run `make install_dev test` which basically installs all the dependencies and runs all the tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model that we want to be able to deploy, we want to make sure that we run end-to-end tests on that model to make sure everything works as expected.\n",
    "\n",
    "For this we will leverage the same framework that the Kubernetes team uses to test Kubernetes itself: KIND.\n",
    "\n",
    "KIND stands for Kubernetes in Docker, and is used to isolate a Kubernetes environent for end-to-end tests.\n",
    "\n",
    "In our case, we will be able to leverage to create an isolated environment, where we'll be able to test our model.\n",
    "\n",
    "For this, the steps we'll have to carry out include:\n",
    "\n",
    "1. Authenticate your docker with the jx CLI\n",
    "2. Add the steps in the `Jenkins-X.yml` to run this in the production cluster\n",
    "3. Leverage the `kind_run_all.sh` script that creates a KIND cluster and runs the tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add docker auth to your cluster\n",
    "\n",
    "Adding a docker authentication with Jenkins X can be done through a JX CLI command, which is the following:\n",
    "\n",
    "* `jx create docker auth --host https://index.docker.io/v1/ --user $YOUR_DOCKER_USERNAME --secret $YOUR_DOCKER_KEY_SECRET --email $YOUR_DOCKER_EMAIL`\n",
    "\n",
    "This comamnd will use these credentials to authenticate with Docker and create an auth token (which expires)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend JenkinsX file for integration\n",
    "\n",
    "Now that we have the test that would run for the integration tests, we need to extend the JX pipeline to run this.\n",
    "\n",
    "This extension is quite simple, and only requires adding the following line:\n",
    "    \n",
    "```\n",
    "            - name: run-end-to-end-tests\n",
    "              command: bash\n",
    "              args:\n",
    "              - integration/kind_test_all.sh\n",
    "```\n",
    "\n",
    "This line would be added in both the PR and release pipelines so that we can run integration tests then.\n",
    "\n",
    "It is also possible to move the integration tests into a separate jenkins-x file such as `jenkins-x-integration.yml` by leveraging [Contexts & Schedules]() which basically allow us to extend the functionality of Prow by writing our own triggers, however this is outside the scope of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config to provide docker authentication\n",
    "\n",
    "This piece is slightly more extensive, as we will need to use Docker to build out containers due to the dependency on `s2i` to build the model wrappers.\n",
    "\n",
    "First we need to define the volumes that we'll be mounting to the container.\n",
    "\n",
    "The first few volumes before basically consist of the core components that docker will need to be able to run.\n",
    "```\n",
    "          volumes:\n",
    "            - name: modules\n",
    "              hostPath:\n",
    "                path: /lib/modules\n",
    "                type: Directory\n",
    "            - name: cgroup\n",
    "              hostPath:\n",
    "                path: /sys/fs/cgroup\n",
    "                type: Directory\n",
    "            - name: dind-storage\n",
    "              emptyDir: {}\n",
    "```\n",
    "We also want to mount the docker credentials which we will generate in the next step.\n",
    "```\n",
    "            - name: jenkins-docker-config-volume\n",
    "              secret:\n",
    "                items:\n",
    "                - key: config.json\n",
    "                  path: config.json\n",
    "                secretName: jenkins-docker-cfg\n",
    "```\n",
    "Once we've created the volumes, now we just need to mount them. This can be done as follows:\n",
    "```\n",
    "        options:\n",
    "          containerOptions:\n",
    "            volumeMounts:\n",
    "              - mountPath: /lib/modules\n",
    "                name: modules\n",
    "                readOnly: true\n",
    "              - mountPath: /sys/fs/cgroup\n",
    "                name: cgroup\n",
    "              - name: dind-storage\n",
    "                mountPath: /var/lib/docker                 \n",
    "```\n",
    "And finally we also mount the docker auth configuration so we don't have to run `docker login`:\n",
    "```\n",
    "              - mountPath: /builder/home/.docker\n",
    "                name: jenkins-docker-config-volume\n",
    "```\n",
    "\n",
    "And to finalise, we need to make sure that the pod can run with privileged context.\n",
    "\n",
    "The reason why this is required is in order to be able to run the docker daemon:\n",
    "```\n",
    "            securityContext:\n",
    "              privileged: true\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kind run all integration tests script\n",
    "\n",
    "The kind_run_all may seem complicated at first, but it's actually quite simple. \n",
    "\n",
    "All the script does is set-up a kind cluster with all dependencies, deploy the model and clean everything up.\n",
    "\n",
    "Let's break down each of the components within the script.\n",
    "\n",
    "#### Start docker\n",
    "\n",
    "We first start the docker daemon and wait until Docker is running (using `docker ps q` for guidance.\n",
    "\n",
    "```\n",
    "# FIRST WE START THE DOCKER DAEMON\n",
    "service docker start\n",
    "# the service can be started but the docker socket not ready, wait for ready\n",
    "WAIT_N=0\n",
    "while true; do\n",
    "    # docker ps -q should only work if the daemon is ready\n",
    "    docker ps -q > /dev/null 2>&1 && break\n",
    "    if [[ ${WAIT_N} -lt 5 ]]; then\n",
    "        WAIT_N=$((WAIT_N+1))\n",
    "        echo \"[SETUP] Waiting for Docker to be ready, sleeping for ${WAIT_N} seconds ...\"\n",
    "        sleep ${WAIT_N}\n",
    "    else\n",
    "        echo \"[SETUP] Reached maximum attempts, not waiting any longer ...\"\n",
    "        break\n",
    "    fi\n",
    "done\n",
    "```\n",
    "\n",
    "#### Create and set-up KIND cluster\n",
    "\n",
    "Once we're running a docker daemon, we can run the command to create our KIND cluster, and install all the components.\n",
    "\n",
    "This will set up a Kubnernetes cluster using the docker daemon (using containers as Nodes), and then install Ambassador + Seldon Core.\n",
    "\n",
    "```\n",
    "#######################################\n",
    "# AVOID EXIT ON ERROR FOR FOLLOWING CMDS\n",
    "set +o errexit\n",
    "\n",
    "# START CLUSTER \n",
    "make kind_create_cluster\n",
    "KIND_EXIT_VALUE=$?\n",
    "\n",
    "# Ensure we reach the kubeconfig path\n",
    "export KUBECONFIG=$(kind get kubeconfig-path)\n",
    "\n",
    "# ONLY RUN THE FOLLOWING IF SUCCESS\n",
    "if [[ ${KIND_EXIT_VALUE} -eq 0 ]]; then\n",
    "    # KIND CLUSTER SETUP\n",
    "    make kind_setup\n",
    "    SETUP_EXIT_VALUE=$?\n",
    "```\n",
    "\n",
    "#### Run python tests\n",
    "\n",
    "We can now run the tests; for this we run all the dev installations and kick off our tests (which we'll add inside of the integration folder).\n",
    "\n",
    "```\n",
    "    # BUILD S2I BASE IMAGES\n",
    "    make build\n",
    "    S2I_EXIT_VALUE=$?\n",
    "\n",
    "    ## INSTALL ALL REQUIRED DEPENDENCIES\n",
    "    make install_integration_dev\n",
    "    INSTALL_EXIT_VALUE=$?\n",
    "    \n",
    "    ## RUNNING TESTS AND CAPTURING ERROR\n",
    "    make test\n",
    "    TEST_EXIT_VALUE=$?\n",
    "fi\n",
    "```\n",
    "\n",
    "#### Clean up\n",
    "\n",
    "Finally we just clean everything, including the cluster, the containers and the docker daemon.\n",
    "\n",
    "```\n",
    "# DELETE KIND CLUSTER\n",
    "make kind_delete_cluster\n",
    "DELETE_EXIT_VALUE=$?\n",
    "\n",
    "#######################################\n",
    "# EXIT STOPS COMMANDS FROM HERE ONWARDS\n",
    "set -o errexit\n",
    "\n",
    "# CLEANING DOCKER\n",
    "docker ps -aq | xargs -r docker rm -f || true\n",
    "service docker stop || true\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promote your application\n",
    "Now that we've verified that our CI pipeline is working, we want to promote our application to production\n",
    "\n",
    "This can be done with our JX CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jx promote application --..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your production application\n",
    "\n",
    "Once your production application is deployed, you can test it using the same script, but in the `jx-production` namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "import numpy as np\n",
    "\n",
    "url = !kubectl get svc ambassador -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'\n",
    "\n",
    "sc = SeldonClient(\n",
    "    gateway=\"ambassador\", \n",
    "    gateway_endpoint=\"localhost:80\",\n",
    "    deployment_name=\"mlops-server\",\n",
    "    payload_type=\"ndarray\",\n",
    "    namespace=\"jx-production\",\n",
    "    transport=\"rest\")\n",
    "\n",
    "response = sc.predict(data=np.array([twenty_test.data[0]]))\n",
    "\n",
    "response.response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sig-mlops",
   "language": "python",
   "name": "sig-mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps with Seldon and Jenkins Classic\n",
    "\n",
    "This repository shows how you can build a Jenkins Classic pipeline to enable Continuous Integration and Continuous Delivery (CI/CD) on your Machine Learning models leveraging Seldon for deployment.\n",
    "This CI/CD pipeline will allow you to:\n",
    "\n",
    "- Run unit tests using Jenkins Classic.\n",
    "- Run end-to-end tests for your model with KIND (Kubernetes in Docker).\n",
    "- Promote your model as a across multiple (staging / prod) environments.\n",
    "\n",
    "To showcase these features we will implement add continuous integration and delivery to three different models. \n",
    "You can find these under the `/models` folder.\n",
    "As we shall see, each of them will require a [different approach to deployment](#Use-Cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CI/CD Pipeline\n",
    "\n",
    "The diagram below provides a high level overview of the CI/CD pipeline.\n",
    "It includes an overview of all the different types of repositories, together with the stakeholders that are the primary contributors of each, as well as the Kubernetes environments in which the applications are deployed.\n",
    "\n",
    "The key pieces to note on the diagram are:\n",
    "\n",
    "- There are different types of environments with different restrictions and behaviours, e.g. staging and production.\n",
    "- It’s possible to have more than one environment for each type (as the type is just what would give it a specific type of config/behaviour).\n",
    "- The environments are by default in the same cluster (as namespaces), however it’s also possible to configure them across different clusters.\n",
    "- Each of the green boxes is a single repository, but it can also have a mono-repo approach, whereby each of the white boxes is a folder within a repo.\n",
    "\n",
    "![CI/CD Pipeline](./images/pipeline-architecture.jpg)\n",
    "\n",
    "**TODO:** Link each type to its own folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model implementation repository\n",
    "\n",
    "From a high-level point of view, when a model implementation repository is updated by a Data Scientist or ML Engineer, the Jenkins CI will push changes to the [GitOps repository](#gitops-repository). This enables the following workflow:\n",
    "\n",
    "1. A Data Scientist or ML Engineer trains a new model.\n",
    "2. The Data Scientist or ML Engineer pushes the updated configuration to the model implementation repository.\n",
    "3. The CI tool automatically builds and tests the model implementation.\n",
    "4. The CI tool automatically pushes the change into the GitOps staging repository.\n",
    "5. The CI tool automatically opens a PR into the GitOps production repository.\n",
    "\n",
    "One key point to highlight which may not be obvious by just looking at the diagram is that in this phase of model implementation, the example above showcases how we can leverage a re-usable model server - that is, reusing a pre-built docker image instead of building one every time.\n",
    "If there are more custom requirements, the user is in full control of the steps performed by the CI Platform Jenkins.\n",
    "This means that it is also possible to build s2i wrapped components which may require training the image every time.\n",
    "\n",
    "#### Why a new repo for every model?\n",
    "\n",
    "A new model implementation repo is currently created because it provides us with a way to separate the “Model Deployment” phase and the “Model Training/Experimentation” phase, and allows us to use the repo as the integration between any frameworks that can serve as sources of models (MLFlow, Kubeflow, Spark, etc).\n",
    "The repo is able to store any metadata, IDs, and configuration files required, and is processed through the CI pipeline every time it is modified. \n",
    "\n",
    "#### Building a docker image in model implementation repository\n",
    "\n",
    "Whilst most of the times users of this approach will be leveraging re-usable model servers such as the SKLearn model server, it is also possible to build a docker image every single time (i.e. build a non-reusable model every time a model changes).\n",
    "This can be be done by adding the relevant steps which would most often include the s2i utility.\n",
    "This may be desired if there are non-standard linux libraries or non-standard depdencies that need to be re-installed every time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitOps repository\n",
    "\n",
    "**TODO:** All resources? Helm charts or just specs?\n",
    "\n",
    "The state of each of our environments (e.g. production or staging) is stored on a GitOps repository.\n",
    "This repository contains all the different Kubernetes resources that have been deployed to each cluster.\n",
    "It is linked through ArgoCD to each of our Kubernetes clusters (or namespaces) so that a change in the repository triggers an update of our environment.\n",
    "\n",
    "When the deployment configuration of a machine learning model implementation is updated, this will automatically make the changes available through a PR to the respective manager/tech-lead/approver.\n",
    "This step will enable the end to end machine learning model promotion to be reviewed and approved by the respective individual.\n",
    "\n",
    "The manager/tech-lead will have to approve the PR before it can be merged.\n",
    "Once it’s approved, it will be merged into the GitOps repo, which will immediately trigger the update in the production namespace/cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Re-usable model server repository\n",
    "\n",
    "If there is a need for a new reusable model server, then it’s possible to do so by creating a repository which would follow a different path.\n",
    "This would be different to the model implementation repository as it would only be built once in a while, whilst the model server would be built multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Set up\n",
    "\n",
    "As a pre-requisite you need to ensure that have access to a Kubernetes cluster.\n",
    "In particular, this guide requires the following pre- requisites:\n",
    "\n",
    "- A Kubernetes cluster running v1.13+.\n",
    "- Jenkins Classic installed in your cluster.\n",
    "- Seldon Core v0.5.1 installed in your cluster.\n",
    "\n",
    "**TODO:** Add note on ArgoCD (or Seldon Deploy??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jenkins Config\n",
    "\n",
    "The configurations required in the Jenkins server are:\n",
    "\n",
    "- Install the GitHub Plugin [(for automated webhook triggers)](https://support.cloudbees.com/hc/en-us/articles/115003015691-GitHub-Webhook-Non-Multibranch-Jobs).\n",
    "- Provide a GitHub token with read access so it can clone relevant repositories.\n",
    "- Set-up webhooks so that GitHub can send push requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Use cases\n",
    "\n",
    "**TODO:** Add links to separate notebooks.\n",
    "\n",
    "This guide goes through three different methods to build and deploy your model.\n",
    "\n",
    "- Using Seldon pre-built re-usable model servers. \n",
    "- Using custom re-usable servers.\n",
    "- Using custom servers with an embedded model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diving into our CI/CD Pipeline\n",
    "\n",
    "On this section we will dive into the internals of the CI/CD pipeline for our [model implementation repositories](#model-implementation-repository).\n",
    "This includes a detailed description of the `Jenkinsfile`, as well as a look into our suggested testing methodology.\n",
    "\n",
    "Note that this will cover a generic example.\n",
    "However, as we shall see, specialising this approach into any of our [three main use cases](#use-cases) will be straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jenkins Pipelines\n",
    "\n",
    "We leverage [Jenkins Pipelines](https://jenkins.io/doc/book/pipeline/) in order to run our continous integration and delivery automation.\n",
    "From a high-level point of view, the pipeline configuration will be responsible for:\n",
    "\n",
    "- Define a **replicable** test and build environment.\n",
    "- Run the unit and integration tests (if applicable).\n",
    "- Promote the application into our staging and production environments.\n",
    "  As discussed [previously](#ci-cd-pipeline), the change will be promoted automatically to the staging environment and will require an approval in the production environment.\n",
    "  \n",
    "We can see a `Jenkinsfile` below taken from the [`news_classifier`](./models/news_classifier) example.\n",
    "This `Jenkinsfile` defines a pipeline which takes into account all of the points mentioned above.\n",
    "The following sections will dive into each of the sections in a much higher detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicable test and build environment\n",
    "\n",
    "In order to ensure that our test environments are versioned and replicable, we make use of the [Jenkins Kubernetes plugin](https://github.com/jenkinsci/kubernetes-plugin).\n",
    "This will allow us to create a Docker image with all the necessary tools for testing and building our models.\n",
    "Using this image, we will then spin up a separate pod, where all our build instructions will be ran.\n",
    "\n",
    "Since it leverages Kubernetes underneath, this also ensure that our CI/CD pipelines are easily scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jenkins-x.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile jenkins-x.yml\n",
    "buildPack: none\n",
    "pipelineConfig:\n",
    "  pipelines:\n",
    "    release:\n",
    "      pipeline:\n",
    "        agent:\n",
    "          image: seldonio/core-builder:0.4\n",
    "        stages:\n",
    "          - name: test-sklearn-server\n",
    "            steps:\n",
    "            - name: run-tests\n",
    "              command: make\n",
    "              args:\n",
    "              - install_dev\n",
    "              - test\n",
    "    pullRequest:\n",
    "      pipeline:\n",
    "        agent:\n",
    "          image: seldonio/core-builder:0.4\n",
    "        stages:\n",
    "          - name: test-sklearn-server\n",
    "            steps:\n",
    "            - name: run-tests\n",
    "              command: make\n",
    "              args:\n",
    "              - install_dev\n",
    "              - test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `jenkins-x.yml` file is pretty easy to understand if we read through the different steps.\n",
    "\n",
    "Basically we can define the steps of what happens upon `release` - i.e. when a PR / Commit is added to master - and what happens upon `pullRequest` - whenever someone opens a pull request.\n",
    "\n",
    "You can see that the steps are exactly the same for both release and PR for now - namely, we run `make install_dev test` which basically installs all the dependencies and runs all the tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration and unit tests\n",
    "\n",
    "Now that we have a model that we want to be able to deploy, we want to make sure that we run end-to-end tests on that model to make sure everything works as expected.\n",
    "For this we will leverage the same framework that the Kubernetes team uses to test Kubernetes itself: [KIND](https://kind.sigs.k8s.io/).\n",
    "\n",
    "KIND stands for Kubernetes-in-Docker, and is used to isolate a Kubernetes environent for end-to-end tests.\n",
    "In our case, we will use this isolated environment to test our model.\n",
    "\n",
    "The steps we'll have to carry out include:\n",
    "\n",
    "1. Enable Docker within your CI/CD pod.\n",
    "2. Add an integration test stage.\n",
    "3. Leverage the `kind_test_all.sh` script that creates a KIND cluster and runs the tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add docker auth to your cluster\n",
    "\n",
    "Adding a docker authentication with Jenkins X can be done through a JX CLI command, which is the following:\n",
    "\n",
    "* `jx create docker auth --host https://index.docker.io/v1/ --user $YOUR_DOCKER_USERNAME --secret $YOUR_DOCKER_KEY_SECRET --email $YOUR_DOCKER_EMAIL`\n",
    "\n",
    "This comamnd will use these credentials to authenticate with Docker and create an auth token (which expires)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extend JenkinsX file for integration\n",
    "\n",
    "Now that we have the test that would run for the integration tests, we need to extend the JX pipeline to run this.\n",
    "\n",
    "This extension is quite simple, and only requires adding the following line:\n",
    "    \n",
    "```\n",
    "            - name: run-end-to-end-tests\n",
    "              command: bash\n",
    "              args:\n",
    "              - integration/kind_test_all.sh\n",
    "```\n",
    "\n",
    "This line would be added in both the PR and release pipelines so that we can run integration tests then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable Docker\n",
    "\n",
    "To test our models, we will need to build their respective containers, for which we will need Docker.\n",
    "\n",
    "In order to do so, we will first need to mount a few volumes into the CI/CD container.\n",
    "These basically consist of the core components that docker will need to be able to run.\n",
    "To mount them we will leverage the `volumes` argument of the `podTemplate()` method:\n",
    "\n",
    "```groovy\n",
    "podTemplate(...,\n",
    "    volumes: [\n",
    "      hostPathVolume(mountPath: '/sys/fs/cgroup', hostPath: '/sys/fs/cgroup'),\n",
    "      hostPathVolume(mountPath: '/lib/modules', hostPath: '/lib/modules'),\n",
    "      emptyDirVolume(mountPath: '/var/lib/docker'),\n",
    "    ])\n",
    "```\n",
    "\n",
    "We then need to make sure that the pod can run with privileged context.\n",
    "This step is required in order to be able to run the `docker` daemon.\n",
    "To enable privileged permissions we will leverage the `privileged` flag of the `containerTemplate()` method and the `yaml` parameter of `podTemplate()`:\n",
    "\n",
    "\n",
    "```groovy\n",
    "podTemplate(...,\n",
    "    containers: [\n",
    "      containerTemplate(\n",
    "          ...,\n",
    "          privileged: true,\n",
    "          ...\n",
    "      ),\n",
    "      ...],\n",
    "    yaml:'''\n",
    "    spec:\n",
    "      securityContext:\n",
    "        fsGroup: 1000\n",
    "      ...\n",
    "    ''',\n",
    "....)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run tests in Kind \n",
    "\n",
    "The `kind_run_all.sh` may seem complicated at first, but it's actually quite simple. \n",
    "All the script does is set-up a kind cluster with all dependencies, deploy the model and clean everything up.\n",
    "Let's break down each of the components within the script.\n",
    "\n",
    "We first start the docker daemon and wait until Docker is running (using `docker ps q` for guidance.\n",
    "\n",
    "```bash\n",
    "# FIRST WE START THE DOCKER DAEMON\n",
    "service docker start\n",
    "# the service can be started but the docker socket not ready, wait for ready\n",
    "WAIT_N=0\n",
    "while true; do\n",
    "    # docker ps -q should only work if the daemon is ready\n",
    "    docker ps -q > /dev/null 2>&1 && break\n",
    "    if [[ ${WAIT_N} -lt 5 ]]; then\n",
    "        WAIT_N=$((WAIT_N+1))\n",
    "        echo \"[SETUP] Waiting for Docker to be ready, sleeping for ${WAIT_N} seconds ...\"\n",
    "        sleep ${WAIT_N}\n",
    "    else\n",
    "        echo \"[SETUP] Reached maximum attempts, not waiting any longer ...\"\n",
    "        break\n",
    "    fi\n",
    "done\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we're running a docker daemon, we can run the command to create our KIND cluster, and install all the components.\n",
    "This will set up a Kubernetes cluster using the docker daemon (using containers as Nodes), and then install Ambassador + Seldon Core.\n",
    "\n",
    "\n",
    "```bash\n",
    "#######################################\n",
    "# AVOID EXIT ON ERROR FOR FOLLOWING CMDS\n",
    "set +o errexit\n",
    "\n",
    "# START CLUSTER \n",
    "make kind_create_cluster\n",
    "KIND_EXIT_VALUE=$?\n",
    "\n",
    "# Ensure we reach the kubeconfig path\n",
    "export KUBECONFIG=$(kind get kubeconfig-path)\n",
    "\n",
    "# ONLY RUN THE FOLLOWING IF SUCCESS\n",
    "if [[ ${KIND_EXIT_VALUE} -eq 0 ]]; then\n",
    "    # KIND CLUSTER SETUP\n",
    "    make kind_setup\n",
    "    SETUP_EXIT_VALUE=$?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the tests; for this we run all the dev installations and kick off our tests (which we'll add inside of the integration folder).\n",
    "\n",
    "```bash\n",
    "    # BUILD S2I BASE IMAGES\n",
    "    make build\n",
    "    S2I_EXIT_VALUE=$?\n",
    "\n",
    "    ## INSTALL ALL REQUIRED DEPENDENCIES\n",
    "    make install_integration_dev\n",
    "    INSTALL_EXIT_VALUE=$?\n",
    "    \n",
    "    ## RUNNING TESTS AND CAPTURING ERROR\n",
    "    make test\n",
    "    TEST_EXIT_VALUE=$?\n",
    "fi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally we just clean everything, including the cluster, the containers and the docker daemon.\n",
    "\n",
    "```bash\n",
    "# DELETE KIND CLUSTER\n",
    "make kind_delete_cluster\n",
    "DELETE_EXIT_VALUE=$?\n",
    "\n",
    "#######################################\n",
    "# EXIT STOPS COMMANDS FROM HERE ONWARDS\n",
    "set -o errexit\n",
    "\n",
    "# CLEANING DOCKER\n",
    "docker ps -aq | xargs -r docker rm -f || true\n",
    "service docker stop || true\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote your application\n",
    "Now that we've verified that our CI pipeline is working, we want to promote our application to production\n",
    "\n",
    "This can be done with our JX CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jx promote application --..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test your production application\n",
    "\n",
    "Once your production application is deployed, you can test it using the same script, but in the `jx-production` namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "import numpy as np\n",
    "\n",
    "url = !kubectl get svc ambassador -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'\n",
    "\n",
    "sc = SeldonClient(\n",
    "    gateway=\"ambassador\", \n",
    "    gateway_endpoint=\"localhost:80\",\n",
    "    deployment_name=\"mlops-server\",\n",
    "    payload_type=\"ndarray\",\n",
    "    namespace=\"jx-production\",\n",
    "    transport=\"rest\")\n",
    "\n",
    "response = sc.predict(data=np.array([twenty_test.data[0]]))\n",
    "\n",
    "response.response.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sig-mlops",
   "language": "python",
   "name": "sig-mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
